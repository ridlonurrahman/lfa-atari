{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "theta = np.array([1,2,3,4,5])\n",
    "phi = np.array([2,2,2,2,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.dot(theta.T, phi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.43941165,  0.48912863])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.uniform(low=0.1, high=0.5, size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from enduro.agent import Agent\n",
    "from enduro.action import Action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.choice(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, -3]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = [phi_position(x), phi_action('BRAKE')]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 6, 5])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(grid_opponents==1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2  2]\n"
     ]
    }
   ],
   "source": [
    "_ = np.where(grid_opponents==1)[1]-np.where(x==2)[0][0]\n",
    "if any(x<=0 and x>-3 for x in _):\n",
    "    print _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def phi_position(grid, act):\n",
    "    grid = grid.tolist()\n",
    "    if grid.index(2)>5:\n",
    "        if act == 0:\n",
    "            return 1\n",
    "        elif act == 2:\n",
    "            return 5\n",
    "        else:\n",
    "            return 1\n",
    "    elif grid.index(2)<4:\n",
    "        if act == 0:\n",
    "            return 1\n",
    "        elif act == 1:\n",
    "            return 5\n",
    "        else:\n",
    "            return 1\n",
    "    else:\n",
    "        if act == 0:\n",
    "            return 10\n",
    "        elif act == 3:\n",
    "            return 1\n",
    "        else:\n",
    "            return 2\n",
    "\n",
    "def phi_action(act):\n",
    "    return 0\n",
    "    if act == 1 or act == 2:\n",
    "        return 2\n",
    "    elif act == 0:\n",
    "        return 5\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "def phi_opponent(grid_agent, grid_opponent, act):\n",
    "    opponents = np.where(grid_opponent==1)[1]\n",
    "    agent = np.where(grid_agent==2)[0][0]\n",
    "    \n",
    "    if any(x>=0 and x<3 for x in opponents-agent):\n",
    "        #print \"WARNING\"\n",
    "        #print opponents\n",
    "        #print agent\n",
    "        if act == 2:\n",
    "            return 20\n",
    "        else:\n",
    "            return 0\n",
    "    elif any(x<=0 and x>-3 for x in opponents-agent):\n",
    "        #print \"WARNING 2\"\n",
    "        #print opponents\n",
    "        #print agent\n",
    "        if act == 1:\n",
    "            return 20\n",
    "        else:\n",
    "            return 0      \n",
    "    else:\n",
    "        if act == 3:\n",
    "            return 0\n",
    "        else:\n",
    "            return 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total reward = 0; Theta = [ 0.1  0.1  0.1]\n",
      "Total reward = 122; Theta = [ 0.09813011  0.1         0.08567354]\n",
      "Total reward = 112; Theta = [ 0.09436119  0.1         0.07382267]\n",
      "Total reward = 99; Theta = [ 0.09043657  0.1         0.06597611]\n",
      "Total reward = 88; Theta = [ 0.08677916  0.1         0.05937009]\n",
      "Total reward = 87; Theta = [ 0.08352485  0.1         0.05256415]\n",
      "Total reward = 80; Theta = [ 0.08009939  0.1         0.04732148]\n",
      "Total reward = 83; Theta = [ 0.07700094  0.1         0.04282258]\n",
      "Total reward = 93; Theta = [ 0.07452787  0.1         0.04085865]\n",
      "Total reward = 78; Theta = [ 0.07170716  0.1         0.03765769]\n",
      "Total reward = 132; Theta = [ 0.07258508  0.1         0.03816399]\n",
      "Total reward = 88; Theta = [ 0.07010158  0.1         0.0353252 ]\n",
      "Total reward = 133; Theta = [ 0.07073339  0.1         0.03621661]\n",
      "Total reward = 94; Theta = [ 0.06960671  0.1         0.03443281]\n",
      "Total reward = 116; Theta = [ 0.069226    0.1         0.03519221]\n",
      "Total reward = 85; Theta = [ 0.0673717   0.1         0.03334917]\n",
      "Total reward = 96; Theta = [ 0.06604654  0.1         0.03395265]\n",
      "Total reward = 80; Theta = [ 0.06440203  0.1         0.03178333]\n",
      "Total reward = 116; Theta = [ 0.06501066  0.1         0.03272351]\n",
      "Total reward = 108; Theta = [ 0.06486297  0.1         0.03313645]\n",
      "Total reward = 85; Theta = [ 0.06346125  0.1         0.03118588]\n",
      "Total reward = 95; Theta = [ 0.06319653  0.1         0.03093806]\n",
      "Total reward = 132; Theta = [ 0.06577719  0.1         0.03227638]\n",
      "Total reward = 105; Theta = [ 0.06531902  0.1         0.03224757]\n",
      "Total reward = 110; Theta = [ 0.06584441  0.1         0.03136214]\n",
      "Total reward = 124; Theta = [ 0.06605473  0.1         0.0333146 ]\n",
      "Total reward = 101; Theta = [ 0.06544671  0.1         0.03297986]\n",
      "Total reward = 93; Theta = [ 0.06496118  0.1         0.03254809]\n",
      "Total reward = 114; Theta = [ 0.06497128  0.1         0.03350116]\n",
      "Total reward = 92; Theta = [ 0.06393861  0.1         0.03240432]\n",
      "Total reward = 95; Theta = [ 0.06352687  0.1         0.03241315]\n",
      "Total reward = 119; Theta = [ 0.06466425  0.1         0.03295105]\n",
      "Total reward = 79; Theta = [ 0.06264285  0.1         0.03127376]\n",
      "Total reward = 75; Theta = [ 0.06124523  0.1         0.02973996]\n",
      "Total reward = 110; Theta = [ 0.06185543  0.1         0.03002732]\n",
      "Total reward = 116; Theta = [ 0.06296913  0.1         0.03089576]\n",
      "Total reward = 106; Theta = [ 0.06302523  0.1         0.03174294]\n",
      "Total reward = 67; Theta = [ 0.05999128  0.1         0.03017519]\n",
      "Total reward = 121; Theta = [ 0.06109118  0.1         0.03155306]\n",
      "Total reward = 83; Theta = [ 0.0599537   0.1         0.03008243]\n",
      "Total reward = 73; Theta = [ 0.05825371  0.1         0.02963084]\n",
      "Total reward = 82; Theta = [ 0.05753892  0.1         0.02996785]\n",
      "Total reward = 113; Theta = [ 0.05964102  0.1         0.03007363]\n",
      "Total reward = 123; Theta = [ 0.06149784  0.1         0.03161529]\n",
      "Total reward = 59; Theta = [ 0.0589249  0.1        0.0288996]\n",
      "Total reward = 135; Theta = [ 0.06149191  0.1         0.03097552]\n",
      "Total reward = 118; Theta = [ 0.0623582   0.1         0.03268626]\n",
      "Total reward = 92; Theta = [ 0.06148231  0.1         0.03257634]\n",
      "Total reward = 145; Theta = [ 0.0641441   0.1         0.03483788]\n",
      "Total reward = 54; Theta = [ 0.0603738   0.1         0.03108546]\n",
      "Total reward = 79; Theta = [ 0.05980253  0.1         0.03041382]\n",
      "Total reward = 89; Theta = [ 0.05900713  0.1         0.03033084]\n",
      "Total reward = 134; Theta = [ 0.06151643  0.1         0.03200501]\n",
      "Total reward = 95; Theta = [ 0.06115655  0.1         0.03144351]\n",
      "Total reward = 53; Theta = [ 0.05857296  0.1         0.02872713]\n",
      "Total reward = 68; Theta = [ 0.05746036  0.1         0.02685679]\n",
      "Total reward = 120; Theta = [ 0.05916582  0.1         0.02907866]\n",
      "Total reward = 130; Theta = [ 0.0615877  0.1        0.0312148]\n",
      "Total reward = 78; Theta = [ 0.06004941  0.1         0.030556  ]\n",
      "Total reward = 75; Theta = [ 0.05847257  0.1         0.02864754]\n",
      "Total reward = 61; Theta = [ 0.05616434  0.1         0.02680969]\n",
      "Total reward = 92; Theta = [ 0.05679613  0.1         0.02746009]\n",
      "Total reward = 71; Theta = [ 0.05494141  0.1         0.02664916]\n",
      "Total reward = 55; Theta = [ 0.05313031  0.1         0.02465439]\n",
      "Total reward = 137; Theta = [ 0.0565187   0.1         0.02879495]\n",
      "Total reward = 81; Theta = [ 0.05636398  0.1         0.02732538]\n",
      "Total reward = 92; Theta = [ 0.05717637  0.1         0.02577658]\n",
      "Total reward = 117; Theta = [ 0.05849562  0.1         0.02829681]\n",
      "Total reward = 138; Theta = [ 0.06095665  0.1         0.03195015]\n",
      "Total reward = 117; Theta = [ 0.06182583  0.1         0.03289866]\n",
      "Total reward = 90; Theta = [ 0.06132513  0.1         0.03194763]\n",
      "Total reward = 95; Theta = [ 0.06064698  0.1         0.03212545]\n",
      "Total reward = 136; Theta = [ 0.06313433  0.1         0.03354331]\n",
      "Total reward = 103; Theta = [ 0.06303309  0.1         0.03279686]\n",
      "Total reward = 91; Theta = [ 0.06254288  0.1         0.03162642]\n",
      "Total reward = 66; Theta = [ 0.06063076  0.1         0.02925706]\n",
      "Total reward = 98; Theta = [ 0.06031054  0.1         0.03035352]\n",
      "Total reward = 125; Theta = [ 0.06212186  0.1         0.03213875]\n",
      "Total reward = 78; Theta = [ 0.06071501  0.1         0.03105255]\n",
      "Total reward = 80; Theta = [ 0.05935363  0.1         0.02955239]\n",
      "Total reward = 85; Theta = [ 0.05894081  0.1         0.02924273]\n",
      "Total reward = 94; Theta = [ 0.058464    0.1         0.02885903]\n",
      "Total reward = 69; Theta = [ 0.05761071  0.1         0.02626588]\n",
      "Total reward = 94; Theta = [ 0.05773379  0.1         0.02701762]\n",
      "Total reward = 112; Theta = [ 0.05862229  0.1         0.02790085]\n",
      "Total reward = 77; Theta = [ 0.05724916  0.1         0.02793232]\n",
      "Total reward = 113; Theta = [ 0.05795107  0.1         0.02991356]\n",
      "Total reward = 81; Theta = [ 0.05716261  0.1         0.02955606]\n",
      "Total reward = 73; Theta = [ 0.05550747  0.1         0.02868475]\n",
      "Total reward = 79; Theta = [ 0.05424478  0.1         0.02781119]\n",
      "Total reward = 108; Theta = [ 0.05568737  0.1         0.02900271]\n",
      "Total reward = 115; Theta = [ 0.05716725  0.1         0.03041854]\n",
      "Total reward = 131; Theta = [ 0.05931432  0.1         0.03270402]\n",
      "Total reward = 110; Theta = [ 0.059862    0.1         0.03379861]\n",
      "Total reward = 84; Theta = [ 0.05926401  0.1         0.03250197]\n",
      "Total reward = 73; Theta = [ 0.0581287   0.1         0.03024016]\n",
      "Total reward = 107; Theta = [ 0.05904566  0.1         0.03067584]\n",
      "Total reward = 92; Theta = [ 0.05929297  0.1         0.02913293]\n",
      "Total reward = 102; Theta = [ 0.05962551  0.1         0.03053875]\n",
      "Total reward = 75; Theta = [ 0.05837404  0.1         0.02964919]\n",
      "Total reward = 104; Theta = [ 0.05893878  0.1         0.03046009]\n",
      "Total reward = 67; Theta = [ 0.05739725  0.1         0.02784103]\n",
      "Total reward = 80; Theta = [ 0.05700834  0.1         0.02672875]\n",
      "Total reward = 112; Theta = [ 0.05820379  0.1         0.02807735]\n",
      "Total reward = 88; Theta = [ 0.05849224  0.1         0.02698182]\n",
      "Total reward = 125; Theta = [ 0.05934096  0.1         0.0308291 ]\n",
      "Total reward = 90; Theta = [ 0.05850914  0.1         0.03076028]\n",
      "Total reward = 92; Theta = [ 0.05886598  0.1         0.02974064]\n",
      "Total reward = 112; Theta = [ 0.05941869  0.1         0.03121339]\n",
      "Total reward = 105; Theta = [ 0.05947981  0.1         0.03190847]\n",
      "Total reward = 136; Theta = [ 0.06141481  0.1         0.033153  ]\n",
      "Total reward = 84; Theta = [ 0.06035922  0.1         0.03214993]\n",
      "Total reward = 93; Theta = [ 0.05994763  0.1         0.03215123]\n",
      "Total reward = 105; Theta = [ 0.06022699  0.1         0.03274374]\n",
      "Total reward = 88; Theta = [ 0.05939014  0.1         0.0318709 ]\n",
      "Total reward = 104; Theta = [ 0.05956831  0.1         0.03101886]\n",
      "Total reward = 112; Theta = [ 0.05971429  0.1         0.03207596]\n",
      "Total reward = 96; Theta = [ 0.05923557  0.1         0.0321991 ]\n",
      "Total reward = 90; Theta = [ 0.05816151  0.1         0.03139017]\n",
      "Total reward = 94; Theta = [ 0.05818192  0.1         0.03029033]\n",
      "Total reward = 65; Theta = [ 0.05665911  0.1         0.02805659]\n",
      "Total reward = 66; Theta = [ 0.05484994  0.1         0.02664588]\n",
      "Total reward = 107; Theta = [ 0.0558857   0.1         0.02809633]\n",
      "Total reward = 97; Theta = [ 0.05618131  0.1         0.03018012]\n",
      "Total reward = 88; Theta = [ 0.05643814  0.1         0.02942746]\n",
      "Total reward = 78; Theta = [ 0.05607391  0.1         0.02801171]\n",
      "Total reward = 78; Theta = [ 0.05498878  0.1         0.02768347]\n",
      "Total reward = 88; Theta = [ 0.05498513  0.1         0.02792469]\n",
      "Total reward = 78; Theta = [ 0.05480481  0.1         0.02768652]\n",
      "Total reward = 144; Theta = [ 0.05751754  0.1         0.03189949]\n",
      "Total reward = 75; Theta = [ 0.05623187  0.1         0.0307825 ]\n",
      "Total reward = 78; Theta = [ 0.05538958  0.1         0.02903733]\n",
      "Total reward = 77; Theta = [ 0.05410824  0.1         0.02866337]\n",
      "Total reward = 94; Theta = [ 0.05519604  0.1         0.02810484]\n",
      "Total reward = 82; Theta = [ 0.05500662  0.1         0.02810261]\n",
      "Total reward = 75; Theta = [ 0.05512838  0.1         0.02603665]\n",
      "Total reward = 124; Theta = [ 0.0573586   0.1         0.02837713]\n",
      "Total reward = 117; Theta = [ 0.05874859  0.1         0.0295435 ]\n",
      "Total reward = 65; Theta = [ 0.05712491  0.1         0.02768074]\n",
      "Total reward = 67; Theta = [ 0.05519022  0.1         0.02610784]\n",
      "Total reward = 120; Theta = [ 0.05746452  0.1         0.02784927]\n",
      "Total reward = 85; Theta = [ 0.05690783  0.1         0.0276978 ]\n",
      "Total reward = 103; Theta = [ 0.05781433  0.1         0.02748108]\n",
      "Total reward = 75; Theta = [ 0.05655395  0.1         0.02665843]\n",
      "Total reward = 46; Theta = [ 0.05413352  0.1         0.02307806]\n",
      "Total reward = 92; Theta = [ 0.05465175  0.1         0.02382833]\n",
      "Total reward = 112; Theta = [ 0.05657146  0.1         0.02620469]\n",
      "Total reward = 75; Theta = [ 0.05558882  0.1         0.02538623]\n",
      "Total reward = 102; Theta = [ 0.05623856  0.1         0.02710927]\n",
      "Total reward = 95; Theta = [ 0.05666028  0.1         0.02721792]\n",
      "Total reward = 116; Theta = [ 0.05825898  0.1         0.02900194]\n",
      "Total reward = 59; Theta = [ 0.056537    0.1         0.02687116]\n",
      "Total reward = 102; Theta = [ 0.05611515  0.1         0.02793709]\n",
      "Total reward = 88; Theta = [ 0.05630888  0.1         0.02763311]\n",
      "Total reward = 76; Theta = [ 0.05520926  0.1         0.02699681]\n",
      "Total reward = 84; Theta = [ 0.05484256  0.1         0.02702456]\n",
      "Total reward = 102; Theta = [ 0.05592201  0.1         0.02787832]\n",
      "Total reward = 112; Theta = [ 0.05735343  0.1         0.02970887]\n",
      "Total reward = 119; Theta = [ 0.05920897  0.1         0.03094551]\n",
      "Total reward = 120; Theta = [ 0.06062208  0.1         0.03192344]\n",
      "Total reward = 119; Theta = [ 0.062551    0.1         0.03236345]\n",
      "Total reward = 93; Theta = [ 0.06225139  0.1         0.03150267]\n",
      "Total reward = 102; Theta = [ 0.06202254  0.1         0.03191345]\n",
      "Total reward = 96; Theta = [ 0.06153715  0.1         0.03159284]\n",
      "Total reward = 65; Theta = [ 0.05959325  0.1         0.02993417]\n",
      "Total reward = 93; Theta = [ 0.05961345  0.1         0.02842822]\n",
      "Total reward = 129; Theta = [ 0.06195643  0.1         0.02999019]\n",
      "Total reward = 91; Theta = [ 0.06081683  0.1         0.03089294]\n",
      "Total reward = 84; Theta = [ 0.06045194  0.1         0.02961837]\n",
      "Total reward = 88; Theta = [ 0.0601271   0.1         0.02976721]\n",
      "Total reward = 106; Theta = [ 0.06129876  0.1         0.02984637]\n",
      "Total reward = 93; Theta = [ 0.0601649   0.1         0.02919558]\n",
      "Total reward = 93; Theta = [ 0.05958927  0.1         0.02939621]\n",
      "Total reward = 87; Theta = [ 0.05939662  0.1         0.02874531]\n",
      "Total reward = 74; Theta = [ 0.05811285  0.1         0.02851005]\n",
      "Total reward = 136; Theta = [ 0.06066799  0.1         0.03114984]\n",
      "Total reward = 78; Theta = [ 0.05933412  0.1         0.0304584 ]\n",
      "Total reward = 72; Theta = [ 0.05770297  0.1         0.02956352]\n",
      "Total reward = 116; Theta = [ 0.05935553  0.1         0.03091982]\n",
      "Total reward = 69; Theta = [ 0.05771751  0.1         0.02894586]\n",
      "Total reward = 90; Theta = [ 0.05740482  0.1         0.02939775]\n",
      "Total reward = 94; Theta = [ 0.05761255  0.1         0.02971379]\n",
      "Total reward = 97; Theta = [ 0.05794486  0.1         0.03046846]\n",
      "Total reward = 89; Theta = [ 0.05728278  0.1         0.03108835]\n",
      "Total reward = 99; Theta = [ 0.05768573  0.1         0.03243778]\n",
      "Total reward = 93; Theta = [ 0.05671559  0.1         0.0332023 ]\n",
      "Total reward = 70; Theta = [ 0.05581086  0.1         0.03160892]\n",
      "Total reward = 95; Theta = [ 0.05544953  0.1         0.03082484]\n",
      "Total reward = 93; Theta = [ 0.05612479  0.1         0.03000152]\n",
      "Total reward = 141; Theta = [ 0.05988026  0.1         0.03211634]\n",
      "Total reward = 67; Theta = [ 0.0586358   0.1         0.02920619]\n",
      "Total reward = 77; Theta = [ 0.05793055  0.1         0.0276572 ]\n",
      "Total reward = 122; Theta = [ 0.05977338  0.1         0.02976946]\n",
      "Total reward = 114; Theta = [ 0.0604397   0.1         0.03182809]\n",
      "Total reward = 96; Theta = [ 0.06052134  0.1         0.03099411]\n",
      "Total reward = 83; Theta = [ 0.05954207  0.1         0.03026364]\n",
      "Total reward = 148; Theta = [ 0.06221073  0.1         0.03363981]\n",
      "Total reward = 92; Theta = [ 0.06065374  0.1         0.03376506]\n",
      "Total reward = 88; Theta = [ 0.06013977  0.1         0.03217792]\n",
      "Total reward = 105; Theta = [ 0.06093436  0.1         0.03175513]\n",
      "Total reward = 101; Theta = [ 0.06078616  0.1         0.03093887]\n",
      "Total reward = 86; Theta = [ 0.05984548  0.1         0.03036959]\n",
      "Total reward = 113; Theta = [ 0.06152852  0.1         0.03041443]\n",
      "Total reward = 102; Theta = [ 0.06134781  0.1         0.03098987]\n",
      "Total reward = 83; Theta = [ 0.06011142  0.1         0.02999397]\n",
      "Total reward = 130; Theta = [ 0.06216493  0.1         0.03192772]\n",
      "Total reward = 116; Theta = [ 0.0625485   0.1         0.03322859]\n",
      "Total reward = 91; Theta = [ 0.06199012  0.1         0.03183514]\n",
      "Total reward = 126; Theta = [ 0.0630226   0.1         0.03343809]\n",
      "Total reward = 124; Theta = [ 0.06434104  0.1         0.03409844]\n",
      "Total reward = 65; Theta = [ 0.062392    0.1         0.03100053]\n",
      "Total reward = 95; Theta = [ 0.06242215  0.1         0.03097915]\n",
      "Total reward = 109; Theta = [ 0.06270147  0.1         0.03129252]\n",
      "Total reward = 80; Theta = [ 0.061041    0.1         0.03086454]\n",
      "Total reward = 80; Theta = [ 0.0593817   0.1         0.02991675]\n",
      "Total reward = 80; Theta = [ 0.05864904  0.1         0.02843584]\n",
      "Total reward = 45; Theta = [ 0.05539688  0.1         0.02586199]\n",
      "Total reward = 63; Theta = [ 0.05352006  0.1         0.02483183]\n",
      "Total reward = 103; Theta = [ 0.05476518  0.1         0.02715592]\n",
      "Total reward = 84; Theta = [ 0.05469166  0.1         0.02602395]\n",
      "Total reward = 112; Theta = [ 0.05612077  0.1         0.02799533]\n",
      "Total reward = 85; Theta = [ 0.05627126  0.1         0.02739817]\n",
      "Total reward = 129; Theta = [ 0.0584091   0.1         0.02926205]\n",
      "Total reward = 105; Theta = [ 0.05962305  0.1         0.02914289]\n",
      "Total reward = 107; Theta = [ 0.06023949  0.1         0.03030179]\n",
      "Total reward = 125; Theta = [ 0.06148864  0.1         0.03157618]\n",
      "Total reward = 102; Theta = [ 0.06146063  0.1         0.0319686 ]\n",
      "Total reward = 121; Theta = [ 0.06268051  0.1         0.03313654]\n",
      "Total reward = 116; Theta = [ 0.06279695  0.1         0.03264804]\n",
      "Total reward = 81; Theta = [ 0.06123741  0.1         0.03134134]\n",
      "Total reward = 85; Theta = [ 0.06025075  0.1         0.03013457]\n",
      "Total reward = 93; Theta = [ 0.05955619  0.1         0.02950295]\n",
      "Total reward = 126; Theta = [ 0.0618172   0.1         0.03107334]\n",
      "Total reward = 122; Theta = [ 0.06334646  0.1         0.03273654]\n",
      "Total reward = 66; Theta = [ 0.06088341  0.1         0.031063  ]\n",
      "Total reward = 67; Theta = [ 0.05863676  0.1         0.02947475]\n",
      "Total reward = 91; Theta = [ 0.05901878  0.1         0.02921292]\n",
      "Total reward = 66; Theta = [ 0.0577748  0.1        0.027439 ]\n",
      "Total reward = 42; Theta = [ 0.05494859  0.1         0.02429878]\n",
      "Total reward = 55; Theta = [ 0.05289055  0.1         0.02319816]\n",
      "Total reward = 70; Theta = [ 0.05286742  0.1         0.02252204]\n",
      "Total reward = 115; Theta = [ 0.05492749  0.1         0.02458709]\n",
      "Total reward = 73; Theta = [ 0.0541672   0.1         0.02424681]\n",
      "Total reward = 136; Theta = [ 0.05716229  0.1         0.02716311]\n",
      "Total reward = 128; Theta = [ 0.0591802   0.1         0.02910762]\n",
      "Total reward = 62; Theta = [ 0.05677119  0.1         0.02726074]\n",
      "Total reward = 97; Theta = [ 0.05698906  0.1         0.0292351 ]\n",
      "Total reward = 122; Theta = [ 0.0582153   0.1         0.03207272]\n",
      "Total reward = 78; Theta = [ 0.05769617  0.1         0.03009166]\n",
      "Total reward = 107; Theta = [ 0.05922248  0.1         0.03055666]\n",
      "Total reward = 74; Theta = [ 0.05829006  0.1         0.02830082]\n",
      "Total reward = 74; Theta = [ 0.05762008  0.1         0.02750532]\n",
      "Total reward = 91; Theta = [ 0.05713973  0.1         0.02849863]\n",
      "Total reward = 96; Theta = [ 0.05778632  0.1         0.02923082]\n",
      "Total reward = 84; Theta = [ 0.05707415  0.1         0.02846508]\n",
      "Total reward = 112; Theta = [ 0.05849421  0.1         0.02952183]\n",
      "Total reward = 73; Theta = [ 0.05684292  0.1         0.02805054]\n",
      "Total reward = 72; Theta = [ 0.0563981  0.1        0.0275885]\n",
      "Total reward = 92; Theta = [ 0.05649129  0.1         0.02845256]\n",
      "Total reward = 93; Theta = [ 0.05670745  0.1         0.02879523]\n",
      "Total reward = 110; Theta = [ 0.05723367  0.1         0.02981778]\n",
      "Total reward = 85; Theta = [ 0.0574763   0.1         0.02868247]\n",
      "Total reward = 72; Theta = [ 0.05656836  0.1         0.02687107]\n",
      "Total reward = 127; Theta = [ 0.05856679  0.1         0.02850874]\n",
      "Total reward = 78; Theta = [ 0.05784169  0.1         0.02823552]\n",
      "Total reward = 104; Theta = [ 0.0585313   0.1         0.03000103]\n",
      "Total reward = 107; Theta = [ 0.05958927  0.1         0.03106675]\n",
      "Total reward = 88; Theta = [ 0.05875309  0.1         0.03007786]\n",
      "Total reward = 52; Theta = [ 0.05640391  0.1         0.02754361]\n",
      "Total reward = 106; Theta = [ 0.05768353  0.1         0.02852733]\n",
      "Total reward = 76; Theta = [ 0.05669038  0.1         0.02745227]\n",
      "Total reward = 109; Theta = [ 0.05766042  0.1         0.02938628]\n",
      "Total reward = 86; Theta = [ 0.05669515  0.1         0.0294051 ]\n",
      "Total reward = 131; Theta = [ 0.05925313  0.1         0.03186079]\n",
      "Total reward = 94; Theta = [ 0.05913985  0.1         0.03133653]\n",
      "Total reward = 107; Theta = [ 0.06048565  0.1         0.03177894]\n",
      "Total reward = 65; Theta = [ 0.05851008  0.1         0.02961856]\n",
      "Total reward = 127; Theta = [ 0.06031257  0.1         0.03073834]\n",
      "Total reward = 118; Theta = [ 0.06125962  0.1         0.03190653]\n",
      "Total reward = 54; Theta = [ 0.05844792  0.1         0.02849314]\n",
      "Total reward = 153; Theta = [ 0.06207818  0.1         0.03151373]\n",
      "Total reward = 85; Theta = [ 0.06143917  0.1         0.03060748]\n",
      "Total reward = 126; Theta = [ 0.06321283  0.1         0.03262424]\n",
      "Total reward = 93; Theta = [ 0.06260151  0.1         0.0311334 ]\n",
      "Total reward = 117; Theta = [ 0.06311463  0.1         0.03216718]\n",
      "Total reward = 92; Theta = [ 0.06245333  0.1         0.03093581]\n",
      "Total reward = 137; Theta = [ 0.06409426  0.1         0.03331868]\n",
      "Total reward = 110; Theta = [ 0.06456509  0.1         0.03324625]\n",
      "Total reward = 69; Theta = [ 0.0629204  0.1        0.030447 ]\n",
      "Total reward = 51; Theta = [ 0.05932908  0.1         0.0288787 ]\n",
      "Total reward = 69; Theta = [ 0.05753458  0.1         0.02746886]\n",
      "Total reward = 113; Theta = [ 0.05922178  0.1         0.02850605]\n",
      "Total reward = 129; Theta = [ 0.06105499  0.1         0.03057605]\n",
      "Total reward = 86; Theta = [ 0.05993893  0.1         0.03113046]\n",
      "Total reward = 74; Theta = [ 0.05844201  0.1         0.02938876]\n",
      "Total reward = 77; Theta = [ 0.05694191  0.1         0.02802126]\n",
      "Total reward = 90; Theta = [ 0.05705461  0.1         0.02789796]\n",
      "Total reward = 92; Theta = [ 0.05736132  0.1         0.02799859]\n",
      "Total reward = 87; Theta = [ 0.05658293  0.1         0.02878259]\n",
      "Total reward = 116; Theta = [ 0.05826179  0.1         0.02956767]\n",
      "Total reward = 81; Theta = [ 0.05770386  0.1         0.02811029]\n",
      "Total reward = 90; Theta = [ 0.05842308  0.1         0.0275663 ]\n",
      "Total reward = 67; Theta = [ 0.05706377  0.1         0.02623442]\n",
      "Total reward = 103; Theta = [ 0.0569519   0.1         0.02692347]\n",
      "Total reward = 104; Theta = [ 0.05724012  0.1         0.02848441]\n",
      "Total reward = 66; Theta = [ 0.05570115  0.1         0.02733815]\n",
      "Total reward = 105; Theta = [ 0.05699808  0.1         0.02817577]\n",
      "Total reward = 85; Theta = [ 0.05721915  0.1         0.02824318]\n",
      "Total reward = 108; Theta = [ 0.05816757  0.1         0.02947419]\n",
      "Total reward = 87; Theta = [ 0.05784186  0.1         0.02857108]\n",
      "Total reward = 91; Theta = [ 0.05741534  0.1         0.02860433]\n",
      "Total reward = 74; Theta = [ 0.05673035  0.1         0.02699825]\n",
      "Total reward = 78; Theta = [ 0.05593404  0.1         0.02776489]\n",
      "Total reward = 78; Theta = [ 0.05473439  0.1         0.02662983]\n",
      "Total reward = 75; Theta = [ 0.05374118  0.1         0.02625089]\n",
      "Total reward = 60; Theta = [ 0.0523018   0.1         0.02425188]\n",
      "Total reward = 105; Theta = [ 0.05302633  0.1         0.02546587]\n",
      "Total reward = 117; Theta = [ 0.05525311  0.1         0.02722613]\n",
      "Total reward = 140; Theta = [ 0.05801642  0.1         0.0300982 ]\n",
      "Total reward = 98; Theta = [ 0.05879961  0.1         0.0303998 ]\n",
      "Total reward = 94; Theta = [ 0.05909384  0.1         0.03146262]\n",
      "Total reward = 73; Theta = [ 0.05787471  0.1         0.0292816 ]\n",
      "Total reward = 64; Theta = [ 0.05655254  0.1         0.0277461 ]\n",
      "Total reward = 113; Theta = [ 0.05819139  0.1         0.02939058]\n",
      "Total reward = 53; Theta = [ 0.05575871  0.1         0.02639987]\n",
      "Total reward = 117; Theta = [ 0.05726124  0.1         0.02820549]\n",
      "Total reward = 104; Theta = [ 0.05818201  0.1         0.0298142 ]\n",
      "Total reward = 93; Theta = [ 0.05812077  0.1         0.02915995]\n",
      "Total reward = 92; Theta = [ 0.05814753  0.1         0.02807228]\n",
      "Total reward = 97; Theta = [ 0.05809143  0.1         0.02814999]\n",
      "Total reward = 138; Theta = [ 0.05968475  0.1         0.03117736]\n",
      "Total reward = 107; Theta = [ 0.06005703  0.1         0.03150268]\n",
      "Total reward = 108; Theta = [ 0.06069274  0.1         0.03169379]\n",
      "Total reward = 75; Theta = [ 0.05904254  0.1         0.0299153 ]\n",
      "Total reward = 121; Theta = [ 0.06040844  0.1         0.03141216]\n",
      "Total reward = 51; Theta = [ 0.05779182  0.1         0.02856354]\n",
      "Total reward = 67; Theta = [ 0.05647311  0.1         0.02802978]\n",
      "Total reward = 73; Theta = [ 0.05570419  0.1         0.026482  ]\n",
      "Total reward = 95; Theta = [ 0.05525051  0.1         0.02853521]\n",
      "Total reward = 87; Theta = [ 0.05517349  0.1         0.02802038]\n",
      "Total reward = 105; Theta = [ 0.05644248  0.1         0.02956647]\n",
      "Total reward = 105; Theta = [ 0.05741587  0.1         0.03017269]\n",
      "Total reward = 109; Theta = [ 0.05837495  0.1         0.03002291]\n",
      "Total reward = 114; Theta = [ 0.05966941  0.1         0.03021704]\n",
      "Total reward = 83; Theta = [ 0.05934599  0.1         0.02805351]\n",
      "Total reward = 47; Theta = [ 0.05605959  0.1         0.0255793 ]\n",
      "Total reward = 86; Theta = [ 0.05634689  0.1         0.02556465]\n",
      "Total reward = 104; Theta = [ 0.05742174  0.1         0.02560064]\n",
      "Total reward = 93; Theta = [ 0.05739204  0.1         0.02702927]\n",
      "Total reward = 55; Theta = [ 0.05481699  0.1         0.02550778]\n",
      "Total reward = 112; Theta = [ 0.05554237  0.1         0.02750708]\n",
      "Total reward = 95; Theta = [ 0.05627481  0.1         0.02712502]\n",
      "Total reward = 87; Theta = [ 0.05652056  0.1         0.02721833]\n",
      "Total reward = 147; Theta = [ 0.0608687   0.1         0.03096079]\n",
      "Total reward = 107; Theta = [ 0.06116262  0.1         0.03085534]\n",
      "Total reward = 88; Theta = [ 0.06099866  0.1         0.03045901]\n",
      "Total reward = 98; Theta = [ 0.06074376  0.1         0.02976845]\n",
      "Total reward = 86; Theta = [ 0.05984254  0.1         0.02876936]\n",
      "Total reward = 130; Theta = [ 0.06201675  0.1         0.03085762]\n",
      "Total reward = 130; Theta = [ 0.06311646  0.1         0.03292029]\n",
      "Total reward = 102; Theta = [ 0.06274937  0.1         0.03331744]\n",
      "Total reward = 111; Theta = [ 0.06307004  0.1         0.03296539]\n",
      "Total reward = 59; Theta = [ 0.06055809  0.1         0.03110844]\n",
      "Total reward = 95; Theta = [ 0.06076556  0.1         0.03114659]\n",
      "Total reward = 74; Theta = [ 0.05921447  0.1         0.02894711]\n",
      "Total reward = 87; Theta = [ 0.05914979  0.1         0.02874424]\n",
      "Total reward = 96; Theta = [ 0.05914967  0.1         0.02892721]\n",
      "Total reward = 82; Theta = [ 0.05874135  0.1         0.02815288]\n",
      "Total reward = 105; Theta = [ 0.05955048  0.1         0.02891181]\n",
      "Total reward = 126; Theta = [ 0.06148442  0.1         0.0299282 ]\n",
      "Total reward = 75; Theta = [ 0.06055201  0.1         0.02871915]\n",
      "Total reward = 103; Theta = [ 0.06129961  0.1         0.02845963]\n",
      "Total reward = 124; Theta = [ 0.06282741  0.1         0.02976468]\n",
      "Total reward = 73; Theta = [ 0.06112574  0.1         0.02817571]\n",
      "Total reward = 82; Theta = [ 0.06083724  0.1         0.02752232]\n",
      "Total reward = 116; Theta = [ 0.06208999  0.1         0.02907593]\n",
      "Total reward = 65; Theta = [ 0.05977228  0.1         0.02789352]\n",
      "Total reward = 61; Theta = [ 0.05752482  0.1         0.02593319]\n",
      "Total reward = 114; Theta = [ 0.05969194  0.1         0.02609803]\n",
      "Total reward = 76; Theta = [ 0.05794697  0.1         0.02624055]\n",
      "Total reward = 93; Theta = [ 0.0582659   0.1         0.02721595]\n",
      "Total reward = 61; Theta = [ 0.0564986   0.1         0.02470878]\n",
      "Total reward = 73; Theta = [ 0.05540561  0.1         0.02525507]\n",
      "Total reward = 81; Theta = [ 0.05511764  0.1         0.02426854]\n",
      "Total reward = 92; Theta = [ 0.05516125  0.1         0.02560925]\n",
      "Total reward = 105; Theta = [ 0.05661423  0.1         0.02649715]\n",
      "Total reward = 114; Theta = [ 0.05809937  0.1         0.02878088]\n",
      "Total reward = 105; Theta = [ 0.05845959  0.1         0.03034323]\n",
      "Total reward = 65; Theta = [ 0.05732396  0.1         0.02790395]\n",
      "Total reward = 66; Theta = [ 0.05554905  0.1         0.0269414 ]\n",
      "Total reward = 107; Theta = [ 0.05668557  0.1         0.02889888]\n",
      "Total reward = 130; Theta = [ 0.05856014  0.1         0.03069263]\n",
      "Total reward = 69; Theta = [ 0.05668064  0.1         0.02870645]\n",
      "Total reward = 102; Theta = [ 0.05813685  0.1         0.02873695]\n",
      "Total reward = 88; Theta = [ 0.05766328  0.1         0.02880648]\n",
      "Total reward = 96; Theta = [ 0.05830659  0.1         0.02943311]\n",
      "Total reward = 83; Theta = [ 0.05730934  0.1         0.02975202]\n",
      "Total reward = 84; Theta = [ 0.05640737  0.1         0.02961051]\n",
      "Total reward = 153; Theta = [ 0.05953672  0.1         0.03407027]\n",
      "Total reward = 100; Theta = [ 0.06030566  0.1         0.03299784]\n",
      "Total reward = 85; Theta = [ 0.05947493  0.1         0.03115258]\n",
      "Total reward = 113; Theta = [ 0.06107988  0.1         0.03073837]\n",
      "Total reward = 98; Theta = [ 0.06090307  0.1         0.03129457]\n",
      "Total reward = 111; Theta = [ 0.06156472  0.1         0.03179921]\n",
      "Total reward = 97; Theta = [ 0.06093109  0.1         0.03306726]\n",
      "Total reward = 69; Theta = [ 0.05866402  0.1         0.03162068]\n",
      "Total reward = 54; Theta = [ 0.05658326  0.1         0.02886699]\n",
      "Total reward = 109; Theta = [ 0.0583202  0.1        0.0305686]\n",
      "Total reward = 131; Theta = [ 0.06114297  0.1         0.03240514]\n",
      "Total reward = 88; Theta = [ 0.06040345  0.1         0.03109486]\n",
      "Total reward = 83; Theta = [ 0.05976822  0.1         0.03020316]\n",
      "Total reward = 92; Theta = [ 0.0599621   0.1         0.02888289]\n",
      "Total reward = 88; Theta = [ 0.05917729  0.1         0.0292457 ]\n",
      "Total reward = 107; Theta = [ 0.05908586  0.1         0.03006103]\n",
      "Total reward = 72; Theta = [ 0.05797857  0.1         0.02859663]\n",
      "Total reward = 73; Theta = [ 0.05652768  0.1         0.02803778]\n",
      "Total reward = 125; Theta = [ 0.05898712  0.1         0.03065872]\n",
      "Total reward = 107; Theta = [ 0.05935973  0.1         0.03082938]\n",
      "Total reward = 87; Theta = [ 0.05900705  0.1         0.02999929]\n",
      "Total reward = 97; Theta = [ 0.05857013  0.1         0.03117603]\n",
      "Total reward = 97; Theta = [ 0.05813023  0.1         0.03129431]\n",
      "Total reward = 95; Theta = [ 0.05716801  0.1         0.03143902]\n",
      "Total reward = 116; Theta = [ 0.05802279  0.1         0.03282308]\n",
      "Total reward = 121; Theta = [ 0.05973793  0.1         0.03395055]\n",
      "Total reward = 116; Theta = [ 0.06064707  0.1         0.03593151]\n",
      "Total reward = 72; Theta = [ 0.05916378  0.1         0.03315248]\n",
      "Total reward = 123; Theta = [ 0.06145301  0.1         0.0333994 ]\n",
      "Total reward = 109; Theta = [ 0.06173366  0.1         0.03330264]\n",
      "Total reward = 59; Theta = [ 0.05874511  0.1         0.03060854]\n",
      "Total reward = 105; Theta = [ 0.05931767  0.1         0.03067938]\n",
      "Total reward = 96; Theta = [ 0.05978009  0.1         0.02966321]\n",
      "Total reward = 124; Theta = [ 0.06120139  0.1         0.03100236]\n",
      "Total reward = 80; Theta = [ 0.06008587  0.1         0.03053614]\n",
      "Total reward = 52; Theta = [ 0.05684905  0.1         0.02842619]\n",
      "Total reward = 105; Theta = [ 0.05792994  0.1         0.02846192]\n",
      "Total reward = 107; Theta = [ 0.05838943  0.1         0.03012193]\n",
      "Total reward = 124; Theta = [ 0.05995758  0.1         0.0316774 ]\n",
      "Total reward = 86; Theta = [ 0.05916486  0.1         0.03019397]\n",
      "Total reward = 131; Theta = [ 0.06112105  0.1         0.0324499 ]\n",
      "Total reward = 100; Theta = [ 0.06121371  0.1         0.03184404]\n",
      "Total reward = 126; Theta = [ 0.06249047  0.1         0.0337448 ]\n",
      "Total reward = 106; Theta = [ 0.06279214  0.1         0.03281525]\n",
      "Total reward = 74; Theta = [ 0.06063671  0.1         0.03129462]\n",
      "Total reward = 105; Theta = [ 0.06084775  0.1         0.03145774]\n",
      "Total reward = 103; Theta = [ 0.06115569  0.1         0.03163496]\n",
      "Total reward = 101; Theta = [ 0.0614875   0.1         0.03113997]\n",
      "Total reward = 112; Theta = [ 0.06239873  0.1         0.0326096 ]\n",
      "Total reward = 57; Theta = [ 0.05978452  0.1         0.03022054]\n",
      "Total reward = 89; Theta = [ 0.06005475  0.1         0.02950362]\n",
      "Total reward = 123; Theta = [ 0.06111859  0.1         0.03154346]\n",
      "Total reward = 103; Theta = [ 0.06153705  0.1         0.03103073]\n",
      "Total reward = 109; Theta = [ 0.06145413  0.1         0.03258256]\n",
      "Total reward = 103; Theta = [ 0.06152095  0.1         0.03272813]\n",
      "Total reward = 106; Theta = [ 0.06243881  0.1         0.03170365]\n",
      "Total reward = 64; Theta = [ 0.06040826  0.1         0.02938722]\n",
      "Total reward = 104; Theta = [ 0.06180853  0.1         0.02920657]\n",
      "Total reward = 128; Theta = [ 0.06311925  0.1         0.03099189]\n",
      "Total reward = 74; Theta = [ 0.06114109  0.1         0.02943179]\n",
      "Total reward = 108; Theta = [ 0.06146044  0.1         0.02977269]\n",
      "Total reward = 58; Theta = [ 0.05920096  0.1         0.02666879]\n",
      "Total reward = 113; Theta = [ 0.06015113  0.1         0.02909283]\n",
      "Total reward = 83; Theta = [ 0.05944863  0.1         0.02828054]\n",
      "Total reward = 103; Theta = [ 0.06011975  0.1         0.02826536]\n",
      "Total reward = 94; Theta = [ 0.060016    0.1         0.02797739]\n",
      "Total reward = 103; Theta = [ 0.06128839  0.1         0.02748737]\n",
      "Total reward = 120; Theta = [ 0.06311589  0.1         0.029108  ]\n",
      "Total reward = 105; Theta = [ 0.06265128  0.1         0.03043861]\n",
      "Total reward = 108; Theta = [ 0.06266151  0.1         0.03140794]\n",
      "Total reward = 74; Theta = [ 0.06057797  0.1         0.03038992]\n",
      "Total reward = 93; Theta = [ 0.06065199  0.1         0.02999537]\n",
      "Total reward = 98; Theta = [ 0.06044316  0.1         0.03005811]\n",
      "Total reward = 143; Theta = [ 0.06267574  0.1         0.03371617]\n",
      "Total reward = 70; Theta = [ 0.06027476  0.1         0.03138399]\n",
      "Total reward = 67; Theta = [ 0.05839304  0.1         0.02919778]\n",
      "Total reward = 80; Theta = [ 0.05790697  0.1         0.02856889]\n",
      "Total reward = 76; Theta = [ 0.05658555  0.1         0.02788819]\n",
      "Total reward = 92; Theta = [ 0.05650077  0.1         0.02808652]\n",
      "Total reward = 87; Theta = [ 0.05641199  0.1         0.02746166]\n",
      "Total reward = 88; Theta = [ 0.05639349  0.1         0.02704116]\n",
      "Total reward = 71; Theta = [ 0.05519967  0.1         0.02502149]\n",
      "Total reward = 72; Theta = [ 0.05412672  0.1         0.02454437]\n",
      "Total reward = 128; Theta = [ 0.05657485  0.1         0.02776397]\n",
      "Total reward = 96; Theta = [ 0.05642816  0.1         0.02744695]\n",
      "Total reward = 108; Theta = [ 0.05782102  0.1         0.02762007]\n",
      "Total reward = 62; Theta = [ 0.05579951  0.1         0.02608791]\n",
      "Total reward = 66; Theta = [ 0.05455     0.1         0.02518724]\n",
      "Total reward = 91; Theta = [ 0.05526352  0.1         0.02552801]\n",
      "Total reward = 126; Theta = [ 0.05768488  0.1         0.0276898 ]\n",
      "Total reward = 84; Theta = [ 0.05705268  0.1         0.02722876]\n",
      "Total reward = 101; Theta = [ 0.05735218  0.1         0.02826423]\n",
      "Total reward = 132; Theta = [ 0.05965352  0.1         0.03110369]\n",
      "Total reward = 65; Theta = [ 0.05816261  0.1         0.02856507]\n",
      "Total reward = 95; Theta = [ 0.05836442  0.1         0.02895398]\n",
      "Total reward = 108; Theta = [ 0.05895598  0.1         0.02973735]\n",
      "Total reward = 65; Theta = [ 0.05797769  0.1         0.02798884]\n",
      "Total reward = 117; Theta = [ 0.05989421  0.1         0.02935422]\n",
      "Total reward = 129; Theta = [ 0.0608506   0.1         0.03162325]\n",
      "Total reward = 92; Theta = [ 0.05997513  0.1         0.03077086]\n",
      "Total reward = 101; Theta = [ 0.06058874  0.1         0.03127548]\n",
      "Total reward = 117; Theta = [ 0.06189799  0.1         0.03179146]\n",
      "Total reward = 82; Theta = [ 0.06035477  0.1         0.03108798]\n",
      "Total reward = 104; Theta = [ 0.06037531  0.1         0.03232257]\n",
      "Total reward = 95; Theta = [ 0.06000279  0.1         0.03253814]\n",
      "Total reward = 104; Theta = [ 0.06063636  0.1         0.03111446]\n",
      "Total reward = 82; Theta = [ 0.05946919  0.1         0.03016084]\n",
      "Total reward = 115; Theta = [ 0.060571    0.1         0.03145853]\n",
      "Total reward = 48; Theta = [ 0.05754725  0.1         0.02810079]\n",
      "Total reward = 85; Theta = [ 0.05755384  0.1         0.02609422]\n",
      "Total reward = 105; Theta = [ 0.05834155  0.1         0.02713811]\n",
      "Total reward = 91; Theta = [ 0.05782117  0.1         0.02748341]\n",
      "Total reward = 134; Theta = [ 0.06018585  0.1         0.03031517]\n",
      "Total reward = 88; Theta = [ 0.05920856  0.1         0.03048869]\n",
      "Total reward = 73; Theta = [ 0.05746076  0.1         0.02934328]\n",
      "Total reward = 97; Theta = [ 0.05777457  0.1         0.02924017]\n",
      "Total reward = 73; Theta = [ 0.05617111  0.1         0.02855675]\n",
      "Total reward = 78; Theta = [ 0.05545022  0.1         0.02771617]\n",
      "Total reward = 145; Theta = [ 0.05924559  0.1         0.03050247]\n",
      "Total reward = 87; Theta = [ 0.05887943  0.1         0.02966489]\n",
      "Total reward = 105; Theta = [ 0.05956919  0.1         0.03059785]\n",
      "Total reward = 115; Theta = [ 0.06052091  0.1         0.0320759 ]\n",
      "Total reward = 82; Theta = [ 0.05994196  0.1         0.03024958]\n",
      "Total reward = 124; Theta = [ 0.06192398  0.1         0.03239876]\n",
      "Total reward = 99; Theta = [ 0.06205098  0.1         0.03180302]\n",
      "Total reward = 110; Theta = [ 0.06235284  0.1         0.03302287]\n",
      "Total reward = 61; Theta = [ 0.05984479  0.1         0.02995995]\n",
      "Total reward = 116; Theta = [ 0.06067495  0.1         0.03184338]\n",
      "Total reward = 109; Theta = [ 0.06194509  0.1         0.03131395]\n",
      "Total reward = 112; Theta = [ 0.06267724  0.1         0.03181886]\n",
      "Total reward = 97; Theta = [ 0.06235914  0.1         0.03194098]\n",
      "Total reward = 105; Theta = [ 0.06233402  0.1         0.03203114]\n",
      "Total reward = 131; Theta = [ 0.06368422  0.1         0.03353028]\n",
      "Total reward = 93; Theta = [ 0.06297124  0.1         0.03337573]\n",
      "Total reward = 75; Theta = [ 0.06178188  0.1         0.0311451 ]\n",
      "Total reward = 80; Theta = [ 0.06088081  0.1         0.03061045]\n",
      "Total reward = 100; Theta = [ 0.06145461  0.1         0.03025893]\n",
      "Total reward = 118; Theta = [ 0.06222328  0.1         0.03100865]\n",
      "Total reward = 145; Theta = [ 0.06576543  0.1         0.03423766]\n",
      "Total reward = 112; Theta = [ 0.06596342  0.1         0.0345651 ]\n",
      "Total reward = 67; Theta = [ 0.0638825   0.1         0.03139158]\n",
      "Total reward = 90; Theta = [ 0.06279131  0.1         0.03076648]\n",
      "Total reward = 56; Theta = [ 0.06002559  0.1         0.02786923]\n",
      "Total reward = 85; Theta = [ 0.05909954  0.1         0.02664408]\n",
      "Total reward = 61; Theta = [ 0.05671812  0.1         0.02583374]\n",
      "Total reward = 69; Theta = [ 0.05457591  0.1         0.02501996]\n",
      "Total reward = 101; Theta = [ 0.05522426  0.1         0.02616134]\n",
      "Total reward = 77; Theta = [ 0.05453194  0.1         0.02575847]\n",
      "Total reward = 77; Theta = [ 0.05434255  0.1         0.02542432]\n",
      "Total reward = 87; Theta = [ 0.05425825  0.1         0.02494256]\n",
      "Total reward = 94; Theta = [ 0.05462593  0.1         0.02590815]\n",
      "Total reward = 68; Theta = [ 0.05342576  0.1         0.02487681]\n",
      "Total reward = 76; Theta = [ 0.0529963   0.1         0.02472462]\n",
      "Total reward = 84; Theta = [ 0.05312481  0.1         0.02477575]\n",
      "Total reward = 125; Theta = [ 0.05595286  0.1         0.02731117]\n",
      "Total reward = 100; Theta = [ 0.05619768  0.1         0.02795905]\n",
      "Total reward = 110; Theta = [ 0.05760773  0.1         0.0287644 ]\n",
      "Total reward = 91; Theta = [ 0.05800406  0.1         0.02878179]\n",
      "Total reward = 85; Theta = [ 0.05807186  0.1         0.0280505 ]\n",
      "Total reward = 90; Theta = [ 0.05834157  0.1         0.02793022]\n",
      "Total reward = 121; Theta = [ 0.05966232  0.1         0.02987304]\n",
      "Total reward = 91; Theta = [ 0.05930441  0.1         0.02936575]\n",
      "Total reward = 92; Theta = [ 0.0585893   0.1         0.02913134]\n",
      "Total reward = 86; Theta = [ 0.05787936  0.1         0.02853689]\n",
      "Total reward = 58; Theta = [ 0.05552773  0.1         0.02659146]\n",
      "Total reward = 94; Theta = [ 0.056183    0.1         0.02678708]\n",
      "Total reward = 101; Theta = [ 0.05692202  0.1         0.02778367]\n",
      "Total reward = 100; Theta = [ 0.05680965  0.1         0.02895028]\n",
      "Total reward = 103; Theta = [ 0.05744777  0.1         0.02894161]\n",
      "Total reward = 78; Theta = [ 0.05663918  0.1         0.02852238]\n",
      "Total reward = 93; Theta = [ 0.05593293  0.1         0.03015306]\n",
      "Total reward = 72; Theta = [ 0.05477678  0.1         0.02906804]\n",
      "Total reward = 90; Theta = [ 0.05536831  0.1         0.02858651]\n",
      "Total reward = 65; Theta = [ 0.05416374  0.1         0.02779373]\n",
      "Total reward = 114; Theta = [ 0.05625796  0.1         0.02941998]\n",
      "Total reward = 105; Theta = [ 0.05744028  0.1         0.03044603]\n",
      "Total reward = 104; Theta = [ 0.05805322  0.1         0.03082028]\n",
      "Total reward = 62; Theta = [ 0.05577784  0.1         0.02956288]\n",
      "Total reward = 99; Theta = [ 0.05574664  0.1         0.0298872 ]\n",
      "Total reward = 93; Theta = [ 0.05592107  0.1         0.03013512]\n",
      "Total reward = 92; Theta = [ 0.05650834  0.1         0.0303844 ]\n",
      "Total reward = 120; Theta = [ 0.0585924  0.1        0.0314764]\n",
      "Total reward = 92; Theta = [ 0.05843924  0.1         0.03092448]\n",
      "Total reward = 90; Theta = [ 0.05827274  0.1         0.03091571]\n",
      "Total reward = 78; Theta = [ 0.05797486  0.1         0.02937831]\n",
      "Total reward = 45; Theta = [ 0.05440229  0.1         0.02679142]\n",
      "Total reward = 100; Theta = [ 0.0554268   0.1         0.02772267]\n",
      "Total reward = 60; Theta = [ 0.05352517  0.1         0.02638358]\n",
      "Total reward = 133; Theta = [ 0.05668671  0.1         0.02883647]\n",
      "Total reward = 118; Theta = [ 0.05868924  0.1         0.03043925]\n",
      "Total reward = 128; Theta = [ 0.06096586  0.1         0.03131809]\n",
      "Total reward = 111; Theta = [ 0.06169128  0.1         0.0323875 ]\n",
      "Total reward = 68; Theta = [ 0.05973803  0.1         0.02991227]\n",
      "Total reward = 89; Theta = [ 0.0592433   0.1         0.02971031]\n",
      "Total reward = 115; Theta = [ 0.05998345  0.1         0.0312113 ]\n",
      "Total reward = 69; Theta = [ 0.05833828  0.1         0.03027993]\n",
      "Total reward = 76; Theta = [ 0.05732882  0.1         0.02910277]\n",
      "Total reward = 109; Theta = [ 0.05910306  0.1         0.02901055]\n",
      "Total reward = 89; Theta = [ 0.0582974   0.1         0.02993687]\n",
      "Total reward = 97; Theta = [ 0.05840206  0.1         0.03055493]\n",
      "Total reward = 81; Theta = [ 0.05721537  0.1         0.02970135]\n",
      "Total reward = 53; Theta = [ 0.05498211  0.1         0.0278075 ]\n",
      "Total reward = 124; Theta = [ 0.05667828  0.1         0.03014141]\n",
      "Total reward = 104; Theta = [ 0.05776643  0.1         0.03024136]\n",
      "Total reward = 66; Theta = [ 0.05645299  0.1         0.02812459]\n",
      "Total reward = 106; Theta = [ 0.05766365  0.1         0.02929943]\n",
      "Total reward = 100; Theta = [ 0.05838095  0.1         0.02990833]\n",
      "Total reward = 98; Theta = [ 0.05858614  0.1         0.02991894]\n",
      "Total reward = 87; Theta = [ 0.05798772  0.1         0.02917852]\n",
      "Total reward = 76; Theta = [ 0.05626915  0.1         0.02829653]\n",
      "Total reward = 108; Theta = [ 0.05740448  0.1         0.02971113]\n",
      "Total reward = 125; Theta = [ 0.05850722  0.1         0.03185503]\n",
      "Total reward = 76; Theta = [ 0.05754155  0.1         0.02992336]\n",
      "Total reward = 55; Theta = [ 0.05474645  0.1         0.02864344]\n",
      "Total reward = 84; Theta = [ 0.05445267  0.1         0.02900605]\n",
      "Total reward = 114; Theta = [ 0.05575871  0.1         0.03072824]\n",
      "Total reward = 95; Theta = [ 0.0561506   0.1         0.03061187]\n",
      "Total reward = 71; Theta = [ 0.05513794  0.1         0.02897685]\n",
      "Total reward = 107; Theta = [ 0.05617835  0.1         0.02963947]\n",
      "Total reward = 107; Theta = [ 0.05691728  0.1         0.03045341]\n",
      "Total reward = 107; Theta = [ 0.057914    0.1         0.03100122]\n",
      "Total reward = 112; Theta = [ 0.05972584  0.1         0.03179806]\n",
      "Total reward = 85; Theta = [ 0.0593328   0.1         0.03034524]\n",
      "Total reward = 63; Theta = [ 0.05710741  0.1         0.02895382]\n",
      "Total reward = 120; Theta = [ 0.05862376  0.1         0.03044159]\n",
      "Total reward = 64; Theta = [ 0.05655009  0.1         0.02799509]\n",
      "Total reward = 105; Theta = [ 0.05800628  0.1         0.02787964]\n",
      "Total reward = 113; Theta = [ 0.059102    0.1         0.02771498]\n",
      "Total reward = 90; Theta = [ 0.05906771  0.1         0.02823084]\n",
      "Total reward = 85; Theta = [ 0.05813069  0.1         0.02787548]\n",
      "Total reward = 44; Theta = [ 0.05525576  0.1         0.02457959]\n",
      "Total reward = 90; Theta = [ 0.05559298  0.1         0.0248581 ]\n",
      "Total reward = 90; Theta = [ 0.05547831  0.1         0.02569294]\n",
      "Total reward = 122; Theta = [ 0.05707392  0.1         0.02799458]\n",
      "Total reward = 103; Theta = [ 0.05867337  0.1         0.02748126]\n",
      "Total reward = 78; Theta = [ 0.05809819  0.1         0.02698533]\n",
      "Total reward = 104; Theta = [ 0.05937742  0.1         0.02785632]\n",
      "Total reward = 126; Theta = [ 0.0613311   0.1         0.03006885]\n",
      "Total reward = 82; Theta = [ 0.06028927  0.1         0.02971316]\n",
      "Total reward = 83; Theta = [ 0.05943103  0.1         0.02941222]\n",
      "Total reward = 94; Theta = [ 0.0589376   0.1         0.02923121]\n",
      "Total reward = 93; Theta = [ 0.05891979  0.1         0.029027  ]\n",
      "Total reward = 85; Theta = [ 0.05821928  0.1         0.02803665]\n",
      "Total reward = 81; Theta = [ 0.05691567  0.1         0.02886211]\n",
      "Total reward = 89; Theta = [ 0.05640859  0.1         0.02844229]\n",
      "Total reward = 69; Theta = [ 0.05480494  0.1         0.02728942]\n",
      "Total reward = 142; Theta = [ 0.05779949  0.1         0.03025781]\n",
      "Total reward = 55; Theta = [ 0.05577887  0.1         0.02707512]\n",
      "Total reward = 93; Theta = [ 0.05641333  0.1         0.02742892]\n",
      "Total reward = 88; Theta = [ 0.05593455  0.1         0.02736309]\n",
      "Total reward = 94; Theta = [ 0.05618693  0.1         0.02761625]\n",
      "Total reward = 116; Theta = [ 0.05872668  0.1         0.02938259]\n",
      "Total reward = 81; Theta = [ 0.05777615  0.1         0.028812  ]\n",
      "Total reward = 94; Theta = [ 0.05780155  0.1         0.02737949]\n",
      "Total reward = 99; Theta = [ 0.05806612  0.1         0.02816328]\n",
      "Total reward = 94; Theta = [ 0.05835246  0.1         0.02750856]\n",
      "Total reward = 91; Theta = [ 0.05843243  0.1         0.02710894]\n",
      "Total reward = 55; Theta = [ 0.05618041  0.1         0.02537349]\n",
      "Total reward = 102; Theta = [ 0.05666542  0.1         0.02690672]\n",
      "Total reward = 89; Theta = [ 0.05677141  0.1         0.02685766]\n",
      "Total reward = 104; Theta = [ 0.05719058  0.1         0.02861794]\n",
      "Total reward = 111; Theta = [ 0.05847228  0.1         0.02979655]\n",
      "Total reward = 100; Theta = [ 0.05883739  0.1         0.03013835]\n",
      "Total reward = 105; Theta = [ 0.05893439  0.1         0.03074419]\n",
      "Total reward = 61; Theta = [ 0.05731909  0.1         0.02842601]\n",
      "Total reward = 110; Theta = [ 0.05883172  0.1         0.02919172]\n",
      "Total reward = 114; Theta = [ 0.06021506  0.1         0.03041467]\n",
      "Total reward = 80; Theta = [ 0.05917503  0.1         0.02891505]\n",
      "Total reward = 95; Theta = [ 0.05983799  0.1         0.02791405]\n",
      "Total reward = 112; Theta = [ 0.06017465  0.1         0.03051431]\n",
      "Total reward = 106; Theta = [ 0.06074427  0.1         0.03082646]\n",
      "Total reward = 95; Theta = [ 0.06047354  0.1         0.03003303]\n",
      "Total reward = 132; Theta = [ 0.06271552  0.1         0.03127514]\n",
      "Total reward = 67; Theta = [ 0.06062348  0.1         0.02963684]\n",
      "Total reward = 104; Theta = [ 0.06162785  0.1         0.02896929]\n",
      "Total reward = 90; Theta = [ 0.06141557  0.1         0.02869228]\n",
      "Total reward = 96; Theta = [ 0.06044395  0.1         0.0297504 ]\n",
      "Total reward = 104; Theta = [ 0.06076577  0.1         0.03002386]\n",
      "Total reward = 128; Theta = [ 0.06192283  0.1         0.03152383]\n",
      "Total reward = 112; Theta = [ 0.0623266   0.1         0.03303901]\n",
      "Total reward = 77; Theta = [ 0.06087932  0.1         0.03049141]\n",
      "Total reward = 91; Theta = [ 0.05993972  0.1         0.03030869]\n",
      "Total reward = 77; Theta = [ 0.05904167  0.1         0.02951518]\n",
      "Total reward = 93; Theta = [ 0.05913812  0.1         0.02900883]\n",
      "Total reward = 88; Theta = [ 0.05864623  0.1         0.02895325]\n",
      "Total reward = 91; Theta = [ 0.05885875  0.1         0.02826012]\n",
      "Total reward = 93; Theta = [ 0.05855268  0.1         0.02828153]\n",
      "Total reward = 63; Theta = [ 0.05710989  0.1         0.02627288]\n",
      "Total reward = 102; Theta = [ 0.05748942  0.1         0.02640495]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-293-ff1eba5bc134>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFunctionApproximationAgent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m     \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepisodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m'Total reward: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_reward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ridlo/rl/rl-cw2/enduro/agent.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, learn, episodes, draw)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m                 \u001b[0;31m# Update the environment grid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m                 \u001b[0;34m(\u001b[0m\u001b[0mroad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_image\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extractor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollision\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ridlo/rl/rl-cw2/enduro/state.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, draw, scale)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__draw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_road_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ridlo/rl/rl-cw2/enduro/state.pyc\u001b[0m in \u001b[0;36m__draw\u001b[0;34m(self, image, scale)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__draw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m         \u001b[0mscaled_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mscaled_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaled_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrefcheck\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "class FunctionApproximationAgent(Agent):\n",
    "    def __init__(self):\n",
    "        super(FunctionApproximationAgent, self).__init__()\n",
    "        # The horizon defines how far the agent can see\n",
    "        self.horizon_row = 5\n",
    "\n",
    "        self.grid_cols = 10\n",
    "        # The state is defined as a tuple of the agent's x position and the\n",
    "        # x position of the closest opponent which is lower than the horizon,\n",
    "        # if any is present. There are four actions and so the Q(s, a) table\n",
    "        # has size of 10 * (10 + 1) * 4 = 440.\n",
    "        self.Q = np.ones((self.grid_cols, self.grid_cols + 1, 4))\n",
    "\n",
    "        # Add initial bias toward moving forward. This is not necessary,\n",
    "        # however it speeds up learning significantly, since the game does\n",
    "        # not provide negative reward if no cars have been passed by.\n",
    "        self.Q[:, :, 0] += 1.\n",
    "\n",
    "        # Helper dictionaries that allow us to move from actions to\n",
    "        # Q table indices and vice versa\n",
    "        self.idx2act = {i: a for i, a in enumerate(self.getActionsSet())}\n",
    "        self.act2idx = {a: i for i, a in enumerate(self.getActionsSet())}\n",
    "\n",
    "        # Learning rate\n",
    "        self.alpha = 0.00001\n",
    "        # Discounting factor\n",
    "        self.gamma = 0.9\n",
    "        # Exploration rate\n",
    "        self.epsilon = 0.01\n",
    "\n",
    "        # Log the obtained reward during learning\n",
    "        self.last_episode = 1\n",
    "        self.episode_log = np.zeros(6510) - 1.\n",
    "        self.log = []\n",
    "        \n",
    "        self.theta = np.random.uniform(low=0.1, high=0.5, size=2)\n",
    "        self.theta = np.array([0.1,0.1,0.1])\n",
    "        self.last_action = 0\n",
    "        self.total_reward = 0\n",
    "\n",
    "    def initialise(self, road, cars, speed, grid):\n",
    "        \"\"\" Called at the beginning of an episode. Use it to construct\n",
    "        the initial state.\n",
    "        \"\"\"\n",
    "        print 'Total reward = '+str(self.total_reward)+\"; Theta = \"+str(self.theta)\n",
    "        self.total_reward = 0\n",
    "        self.next_state2 = grid[:5]\n",
    "\n",
    "    def act(self):\n",
    "        \"\"\" Implements the decision making process for selecting\n",
    "        an action. Remember to store the obtained reward.\n",
    "        \"\"\"\n",
    "\n",
    "        self.state2 = self.next_state2\n",
    "\n",
    "        # If exploring\n",
    "        if np.random.uniform(0., 1.) < self.epsilon:\n",
    "            # Select a random action using softmax\n",
    "            idx = np.random.choice(4)#, p=probs)\n",
    "            self.action = self.idx2act[idx]\n",
    "            self.last_action = idx\n",
    "        else:\n",
    "            # Select the greedy action\n",
    "            idx = self.argmax_Qsa(self.state2)\n",
    "            #print idx\n",
    "            self.action = self.idx2act[idx]\n",
    "            self.last_action = idx\n",
    "\n",
    "        self.reward = self.move(self.action)\n",
    "        self.total_reward += self.reward\n",
    "\n",
    "    def sense(self, road, cars, speed, grid):\n",
    "        \"\"\" Constructs the next state from sensory signals.\n",
    "\n",
    "        Args:\n",
    "            road  -- 2-dimensional array containing [x, y] points\n",
    "                     in pixel coordinates of the road grid\n",
    "            cars  -- dictionary which contains the location and the size\n",
    "                     of the agent and the opponents in pixel coordinates\n",
    "            speed -- the relative speed of the agent with respect the others\n",
    "            gird  -- 2-dimensional numpy array containing the latest grid\n",
    "                     representation of the environment\n",
    "\n",
    "        For more information on the arguments have a look at the README.md\n",
    "        \"\"\"\n",
    "        self.next_state2 = grid[:5]\n",
    "\n",
    "        # Visualise the environment grid\n",
    "        #cv2.imshow(\"Enduro\", self._image)\n",
    "\n",
    "    def learn(self):\n",
    "        \"\"\" Performs the learning procedure. It is called after act() and\n",
    "        sense() so you have access to the latest tuple (s, s', a, r).\n",
    "        \"\"\"\n",
    "        #print \"last action = \"+str(self.last_action)\n",
    "        #print \"state2 = \"+str(self.state2)\n",
    "        _max_Qsa = self.max_Qsa(self.next_state2)\n",
    "        self.phi = [phi_position(self.state2[0], self.last_action), phi_action(self.last_action),\n",
    "                   phi_opponent(self.state2[0], self.state2[1:], self.last_action)]\n",
    "        \n",
    "        Q_sa = np.dot(self.theta.T, self.phi)\n",
    "        #print str(Q_sa)+\" = \"+str(self.theta)+' * '+str(self.phi)\n",
    "        \n",
    "        \n",
    "        '''print \"grad = \" + str(np.dot(self.alpha*(self.reward + self.gamma * _max_Qsa - Q_sa),\n",
    "                                    self.phi)) + \" = \" + str(\n",
    "            self.alpha*(self.reward + self.gamma * _max_Qsa - Q_sa)) + \" * \" + str(\n",
    "        self.phi)'''\n",
    "        \n",
    "        self.theta = self.theta + np.dot(self.alpha*(self.reward + self.gamma * _max_Qsa - Q_sa), self.phi)\n",
    "        \n",
    "        #print \"Updated theta = \"+str(self.theta)\n",
    "        \n",
    "        #Q_sa = self.Q[self.state[0], self.state[1], self.act2idx[self.action]]\n",
    "\n",
    "        # Calculate the updated state action value\n",
    "        #Q_sa_new = Q_sa + self.alpha * (self.reward + self.gamma * self.maxQsa(self.next_state) - Q_sa)\n",
    "\n",
    "        # Write the updated value\n",
    "        #self.Q[self.state[0], self.state[1], self.act2idx[self.action]] = Q_sa_new\n",
    "        pass\n",
    "\n",
    "    def callback(self, learn, episode, iteration):\n",
    "        \"\"\" Called at the end of each timestep for reporting/debugging purposes.\n",
    "        \"\"\"\n",
    "        #if not iteration%1000:\n",
    "        #    print \"{0}/{1}: {2}\".format(episode, iteration, self.total_reward)\n",
    "\n",
    "        #if not episode % 100:\n",
    "        cv2.imshow(\"Enduro\", self._image)\n",
    "        #cv2.waitKey(1)\n",
    "\n",
    "    def QsaAll(self, grid):\n",
    "        self.allQsa = []\n",
    "        for each in [0,1,2,3]:\n",
    "            self.phi = [phi_position(grid[0], each), phi_action(each), \n",
    "                        phi_opponent(grid[0], grid[1:], each)]\n",
    "            _ = np.dot(self.theta.T, self.phi)\n",
    "            self.allQsa.append(_)\n",
    "        #print self.allQsa\n",
    "        #print 'MAX = ' + str(np.max(self.allQsa))\n",
    "        #print 'ARD MAX = ' + str(np.argmax(self.allQsa))\n",
    "        return self.allQsa\n",
    "    \n",
    "    def max_Qsa(self, grid):\n",
    "        return np.max(self.QsaAll(grid))\n",
    "    def argmax_Qsa(self, grid):\n",
    "        return np.argmax(self.QsaAll(grid))\n",
    "    \n",
    "    def maxQsa(self, state):\n",
    "        return np.max(self.Q[state[0], state[1], :])\n",
    "\n",
    "    def argmaxQsa(self, state):\n",
    "        return np.argmax(self.Q[state[0], state[1], :])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    a = FunctionApproximationAgent()\n",
    "    a.run(True, episodes=2000, draw=True)\n",
    "    print 'Total reward: ' + str(a.total_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/2000: 5\n",
      "1/3000: 14\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-225-832213c6f858>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFunctionApproximationAgent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m     \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepisodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m'Total reward: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_reward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ridlo/rl/rl-cw2/enduro/agent.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, learn, episodes, draw)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m                 \u001b[0;31m# Update the environment grid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m                 \u001b[0;34m(\u001b[0m\u001b[0mroad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_image\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extractor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollision\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ridlo/rl/rl-cw2/enduro/state.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, draw, scale)\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_road_grid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__detectRoadGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         self._cars = self.__detectCars(\n\u001b[0;32m---> 51\u001b[0;31m             img * self.__getRoadMask(img, self._road_grid))\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state_grid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getStateGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_road_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ridlo/rl/rl-cw2/enduro/state.pyc\u001b[0m in \u001b[0;36m__detectCars\u001b[0;34m(self, image)\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;31m# Detect the contour of the player's car\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         _, thresh = cv2.threshold(\n\u001b[0;32m--> 141\u001b[0;31m             cv2.cvtColor(image * mask, cv2.COLOR_BGR2GRAY), 170, 255, 0)\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_cv3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
